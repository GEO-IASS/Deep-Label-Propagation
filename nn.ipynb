{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iris_data():\n",
    "    \"\"\" Read the iris data and label/unlabel data points\"\"\"\n",
    "    # load iris data\n",
    "    iris   = datasets.load_iris()\n",
    "    data   = iris[\"data\"]\n",
    "    labels = iris[\"target\"]\n",
    "    \n",
    "    # get label 0 and 1, and corresponding data\n",
    "    labels = labels[labels < 2]\n",
    "    data = data[np.where(labels < 2)]\n",
    "    \n",
    "    # generate random numbers for unlabeling\n",
    "    rng = np.random.RandomState(42)\n",
    "    random_unlabeled_points = rng.rand(len(labels)) < 0.5\n",
    "    masked_labels = np.copy(labels).astype(float)\n",
    "    \n",
    "    # keep labels for points that will be unlabeled\n",
    "    unlabeled_y_sol = np.copy(labels[random_unlabeled_points])\n",
    "\n",
    "    # unlabel points\n",
    "    masked_labels[random_unlabeled_points] = 0.5\n",
    "    \n",
    "    unlabeled_indices = np.where(random_unlabeled_points)\n",
    "    \n",
    "    # separate labeled/unlabeled Y\n",
    "    unlabeled_y = masked_labels[random_unlabeled_points]\n",
    "    labeled_y = np.delete(masked_labels,unlabeled_indices)\n",
    "    \n",
    "    # separate labeled/unlabeled X\n",
    "    unlabeled_X = data[unlabeled_indices]\n",
    "    labeled_X = np.delete(data,unlabeled_indices,axis=0)\n",
    "    \n",
    "    return labeled_X, labeled_y, unlabeled_X, unlabeled_y, unlabeled_y_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_symmetric(a, tol=1e-8):\n",
    "    return np.allclose(a, a.T, atol=tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights(X):\n",
    "    \n",
    "    def get_neighbors(arr,threshold=0.95):\n",
    "        # index = arr.argsort()[:-5][::-1]\n",
    "        index = np.where(arr > 0.95)\n",
    "        arr[index] = 0\n",
    "        return arr\n",
    "    \n",
    "    # use rdf kernel to estimate weights\n",
    "    pairwise_dists = squareform(pdist(X, 'euclidean'))\n",
    "    s = np.var(X)\n",
    "    K = sp.exp(-pairwise_dists ** 2 / s ** 2)\n",
    "    np.fill_diagonal(K, 0)\n",
    "    K = np.apply_along_axis(get_neighbors, 0, K)\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_graph_with_labels(adjacency_matrix):\n",
    "    rows, cols = np.where(adjacency_matrix > 0)\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    gr = nx.Graph()\n",
    "    gr.add_edges_from(edges)\n",
    "    nx.draw_networkx(gr,node_size=50,with_labels=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_propagation(X,Ly,Uy):\n",
    "    W = get_weights(X)\n",
    "    T = W / np.sum(W, axis=1)\n",
    "    Tnorm = T / np.sum(T, axis=1)\n",
    "    Tuu_norm = Tnorm[len(LX):,len(LX):]\n",
    "    Tul_norm = Tnorm[len(LX):,:len(LX)]\n",
    "    Uy_lp = inv((np.identity(len(Tuu_norm))-Tuu_norm)) @ Tul_norm @ Ly\n",
    "    return Uy_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_propagation_iter(X,Ly,Uy,iter_):\n",
    "    W = get_weights(X)\n",
    "    T = W / np.sum(W, axis=1)\n",
    "\n",
    "    Y = np.hstack((Ly,Uy))\n",
    "    print(Y.shape)\n",
    "\n",
    "    for i in range(iter_):\n",
    "        Y = np.dot(T,Y)\n",
    "        Y[:len(Ly)] = Ly\n",
    "\n",
    "    return(Y[len(Ly):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LX, Ly, UX, Uy, Uy_sol = get_iris_data()\n",
    "features = np.vstack((LX,UX))\n",
    "labels = np.hstack((Ly,Uy))\n",
    "labels_sol = np.hstack((Ly,Uy_sol))\n",
    "weights = get_weights(features)\n",
    "num_labeled = len(Ly)\n",
    "num_unlabeled = len(Uy)\n",
    "num_nodes = num_labeled+num_unlabeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52830188679245282"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.rint(Uy) == Uy_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Uy_lp = label_propagation(features,Ly,Uy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73584905660377353"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.rint(Uy_lp) == Uy_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "Uy_lp_iter = label_propagation_iter(features,Ly,Uy,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73584905660377353"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.rint(Uy_lp_iter) == Uy_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8867924528301887"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.rint(Uy_lp_iter) == np.rint(Uy_lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create input matrix \n",
    "LY = np.tile(Ly,(Ly.shape[0],1))\n",
    "UY = np.tile(Uy,(Ly.shape[0],1))\n",
    "\n",
    "# mask diagonal elements for labeled data\n",
    "np.fill_diagonal(LY, 0.5)\n",
    "\n",
    "label_input = np.hstack((LY, UY))\n",
    "label_input_test = np.hstack((Ly,Uy))\n",
    "\n",
    "unlabeled_ = np.hstack((np.identity(LY.shape[0]),np.ones((Ly.shape[0],Uy.shape[0]))))\n",
    "unlabeled_test = np.hstack((np.zeros(LY.shape[0]),np.ones((Uy.shape[0]))))\n",
    "\n",
    "labeled_ = 1 - unlabeled_\n",
    "labeled_test = 1 - unlabeled_test\n",
    "\n",
    "masked_ = np.hstack((np.identity(LY.shape[0]),np.zeros((Ly.shape[0],Uy.shape[0]))))\n",
    "\n",
    "# TODO: shaffle input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NN without features ##\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def init_weights(weights_np):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.convert_to_tensor(weights_np, np.float32)\n",
    "    return tf.Variable(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop(X, w, T, one_hot, reverse_one_hot):\n",
    "    normalized_w = w / tf.reduce_sum(w, axis = 1)\n",
    "    trueX = X\n",
    "    for i in range(T):\n",
    "        h = tf.tensordot(X, normalized_w, axes = 1)\n",
    "        h = tf.multiply(h, unlabeled) + tf.multiply(trueX, labeled)\n",
    "        X = h\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Layer's sizes\n",
    "T = 1\n",
    "x_size = num_nodes # Number of input nodes: number of labeled nodes\n",
    "h_size = num_nodes # Number of hidden nodes: number of labeled nodes\n",
    "y_size = num_nodes # Number of outcomes: number of labeled nodes\n",
    "\n",
    "# Symbols\n",
    "X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "unlabeled = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "labeled = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "masked = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "# Weight initializations\n",
    "w = init_weights(weights)\n",
    "\n",
    "# Forward propagation\n",
    "yhat    = forwardprop(X, w, T, unlabeled, labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "a = yhat\n",
    "cost = tf.reduce_mean(tf.multiply(masked, tf.multiply(y, tf.log(yhat))))\n",
    "updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_output = np.tile(labels,(label_input.shape[0],1))\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "pred = sess.run(yhat, feed_dict={X:label_input_test.reshape(1,100),\n",
    "                            y:label_output[1:2],\n",
    "                            unlabeled:unlabeled_test.reshape(1,100), \n",
    "                            labeled:labeled_test.reshape(1,100),\n",
    "                            masked:masked_})\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63205785,  0.65269452,  0.48617205,  0.62007231,  0.51780617,\n",
       "         0.48384222,  0.41829225,  0.42737427,  0.46051186,  0.47398618,\n",
       "         0.55859816,  0.61287117,  0.51327324,  0.63316816,  0.62441987,\n",
       "         0.63727266,  0.65139943,  0.59741127,  0.45018771,  0.53588921,\n",
       "         0.65993875,  0.63687885,  0.64576942,  0.43879244,  0.54238153,\n",
       "         0.50175887,  0.54327172,  0.66183281,  0.55509508,  0.51465738,\n",
       "         0.55217838,  0.50951147,  0.53151327,  0.50645667,  0.52554333,\n",
       "         0.50762373,  0.56985164,  0.60600609,  0.44995159,  0.60664725,\n",
       "         0.60118467,  0.50075853,  0.49210307,  0.50340104,  0.63130033,\n",
       "         0.58319086,  0.53866142,  0.51396751,  0.5143382 ,  0.5164274 ,\n",
       "         0.49103931,  0.51721019,  0.49282163]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:,47:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uy_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54716981132075471"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.rint(pred[:,47:]) == Uy_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run SGD\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "label_output = np.reshape(labels,(1,len(labels)))\n",
    "\n",
    "for epoch in range(1):\n",
    "    # Train with each example\n",
    "    for i in range(len(LY)):\n",
    "        \n",
    "        sess.run(yhat, feed_dict={X:label_input[i: i + 1],\n",
    "                                y:label_output,\n",
    "                                one_hot:one_hot_[i: i + 1], \n",
    "                                reverse_one_hot:reverse_one_hot_[i: i + 1]})\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_output = np.reshape(labels,(1,len(labels))),one_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NN with features ##\n",
    "\n",
    "def forwardprop_with_features(X, T, Features, Theta):\n",
    "    \n",
    "    w = tf.sigmoid(tf.transpose(Features) * Theta * Features)\n",
    "    \n",
    "    normalized_w = w / tf.reduce_sum(w, axis = 1)\n",
    "    for i in range(T):\n",
    "        h = X * normalized_w\n",
    "        #normalized_h = h / tf.reshape(tf.reduce_sum(h,axis=1),[47,1])\n",
    "        X = h\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-be9ac9457b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Layer's sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;31m# Number of input nodes: number of labeled nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mh_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;31m# Number of hidden nodes: number of labeled nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# Layer's sizes\n",
    "T = 2\n",
    "num_features = features.shape[1]\n",
    "x_size = num_nodes # Number of input nodes: number of labeled nodes\n",
    "h_size = num_nodes # Number of hidden nodes: number of labeled nodes\n",
    "y_size = num_nodes # Number of outcomes: number of labeled nodes\n",
    "\n",
    "# Symbols\n",
    "X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "one_hot = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "Features = tf.constant(features)\n",
    "\n",
    "# Weight initializations # TODO num_features\n",
    "Theta = tf.Variable(tf.cast(tf.diag(np.random.uniform(size=num_features)),tf.float32))\n",
    "print(Theta)\n",
    "# Forward propagation\n",
    "yhat    = forwardprop_with_features(X, T, Features, Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "cost = tf.reduce_mean(tf.multiply(one_hot,tf.multiply(y, tf.log(yhat))))\n",
    "#cost = tf.reduce_mean(tf.multiply(one_hot,tf.multiply(y, tf.log(yhat))))\n",
    "updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Run SGD\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(1):\n",
    "    # Train with each example\n",
    "    for i in range(len(LY)):\n",
    "        X_ = np.hstack((LY_input[i: i + 1][0][:num_labeled],Uy))\n",
    "        X_ = np.reshape(X_,(1,len(X_)))\n",
    "        y_ = np.hstack((Ly,Uy))\n",
    "        y_ = np.reshape(X_,(1,len(y_)))\n",
    "        one_hot_ = np.hstack((LY_input[i: i + 1][0][num_labeled:],np.zeros(len(Uy))))\n",
    "        one_hot_ = np.reshape(one_hot_,(1,len(one_hot_)))\n",
    "        print(sess.run(updates, feed_dict={X:X_ , y:y_ , one_hot:one_hot_}))\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
